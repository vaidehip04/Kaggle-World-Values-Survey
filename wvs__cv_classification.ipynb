{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython version:       7.8.0 (need at least 1.0)\n",
      "Numpy version:        1.16.5 (need at least 1.7.1)\n",
      "SciPy version:         1.3.1 (need at least 0.12.0)\n",
      "Pandas version:       0.25.1 (need at least 0.11.0)\n",
      "Mapltolib version:     3.1.1 (need at least 1.2.1)\n",
      "Scikit-Learn version: 0.21.3 (need at least 0.13.1)\n"
     ]
    }
   ],
   "source": [
    "#IPython is what you are using now to run the notebook\n",
    "import IPython\n",
    "print( \"IPython version:      %6.6s (need at least 1.0)\" % IPython.__version__)\n",
    "\n",
    "# Numpy is a library for working with arrays and matrices\n",
    "import numpy as np\n",
    "print( \"Numpy version:        %6.6s (need at least 1.7.1)\" % np.__version__)\n",
    "\n",
    "# SciPy implements many different numerical algorithms\n",
    "import scipy as sp\n",
    "print( \"SciPy version:        %6.6s (need at least 0.12.0)\" % sp.__version__)\n",
    "\n",
    "# Pandas makes working with data tables easier\n",
    "import pandas as pd\n",
    "print( \"Pandas version:       %6.6s (need at least 0.11.0)\" % pd.__version__)\n",
    "\n",
    "# Module for plotting\n",
    "import matplotlib.pyplot as plt  \n",
    "from pylab import *\n",
    "print( \"Mapltolib version:    %6.6s (need at least 1.2.1)\" %\n",
    "       matplotlib.__version__)\n",
    "%matplotlib inline\n",
    "# necessary for in-line graphics\n",
    "\n",
    "# SciKit Learn implements several Machine Learning algorithms\n",
    "import sklearn\n",
    "print( \"Scikit-Learn version: %6.6s (need at least 0.13.1)\" %\n",
    "       sklearn.__version__)\n",
    "import os\n",
    "# for certain system-related functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Explore and prepare the data (20pt)\n",
    "As the first step, explore the data.\n",
    "\n",
    "Q1. (2pt) Load the data. How many responses and variables do we have?\n",
    "\n",
    "Answer 1:\n",
    "\n",
    "The dataset World Values Survey data has 90350 responses (rows) and 328 variables (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   V2  V4  V5  V6  V7  V8  V9  V10  V11  V12  ...  MN_228S8  MN_229A  MN_230A  \\\n",
      "0  12   1   1   1  -2   1   1    2    1    1  ...         3       -3       -3   \n",
      "1  12   1   2   3   4   2   2    2    2    2  ...         3       -3       -3   \n",
      "2  12   1   3   2   4   2   1    2    2    2  ...         4        1        1   \n",
      "3  12   1   1   3   4   3   1    2    1    2  ...         2        2        1   \n",
      "4  12   1   1   1   2   1   1    1    3    2  ...         2        2        1   \n",
      "\n",
      "   MN_233A  MN_237B1  MN_249A1  MN_249A3  I_RELIGBEL  I_NORM1  I_VOICE1  \n",
      "0       -3        -3         1         1         0.0      1.0      0.00  \n",
      "1       -3        -3         2        -1         0.0      1.0      0.66  \n",
      "2        2        -3         1         1         0.0      1.0      0.33  \n",
      "3        2        -3         1         2         0.0      1.0      0.00  \n",
      "4        2        -3         1         2         0.0      1.0      0.66  \n",
      "\n",
      "[5 rows x 328 columns]\n",
      "\n",
      " The nmber of rows and columns are : \n",
      "\n",
      "(90350, 328)\n"
     ]
    }
   ],
   "source": [
    "# Reading the world Value data\n",
    "wvs_df = pd.read_csv('C:/Users/vaide/Documents/574-DS2/ps4/wvs.csv.bz2', sep ='\\t')\n",
    "\n",
    "#Exploring the data\n",
    "print(wvs_df.head())\n",
    "print(\"\\n The nmber of rows and columns are : \\n\")\n",
    "\n",
    "print(wvs_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. (3pt) Create a summary table over all responses for V204 : is abortion justifiable. How many nonmissing responses (i.e. positive answers) do you find? Describe the the opinion about the abortion among the global pool of respondents.\n",
    "\n",
    "Answer 2:\n",
    "There are 85742 non-missing responses and 4608 missing responses for the V204 variable.\n",
    "\n",
    "Opinion about abortion among the global pool of respondents is :\n",
    "\n",
    "About 60% of the global pool of respondents think that abortion is not justifiable (rating 1-3).\n",
    "\n",
    "About 10% of the global pool of respondents think that abortion is justifiable (rating 8-10).\n",
    "\n",
    "About 5% of the global pool of respondents had given inapplicable/missing responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Responses</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Non-Missing</td>\n",
       "      <td>85742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Missing</td>\n",
       "      <td>4608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Responses  Count\n",
       "0  Non-Missing   85742\n",
       "1       Missing   4608"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the count for both missing and non-misising responses\n",
    "data = [[\"Non-Missing \", len(wvs_df[wvs_df.V204 > 0])],[\"Missing\",len(wvs_df[wvs_df.V204 < 0])]]\n",
    "data_pd = pd.DataFrame(data, columns=[\"Responses\",\"Count\"])\n",
    "data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage_Opinion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V204</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>-5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.025457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-4</td>\n",
       "      <td>1523</td>\n",
       "      <td>1.685667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-2</td>\n",
       "      <td>1045</td>\n",
       "      <td>1.156613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-1</td>\n",
       "      <td>2017</td>\n",
       "      <td>2.232429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>40227</td>\n",
       "      <td>44.523520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7896</td>\n",
       "      <td>8.739347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6294</td>\n",
       "      <td>6.966242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4497</td>\n",
       "      <td>4.977310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>9580</td>\n",
       "      <td>10.603210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4395</td>\n",
       "      <td>4.864416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3493</td>\n",
       "      <td>3.866076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3397</td>\n",
       "      <td>3.759823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1896</td>\n",
       "      <td>2.098506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4067</td>\n",
       "      <td>4.501384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count  Percentage_Opinion\n",
       "V204                           \n",
       "-5       23            0.025457\n",
       "-4     1523            1.685667\n",
       "-2     1045            1.156613\n",
       "-1     2017            2.232429\n",
       " 1    40227           44.523520\n",
       " 2     7896            8.739347\n",
       " 3     6294            6.966242\n",
       " 4     4497            4.977310\n",
       " 5     9580           10.603210\n",
       " 6     4395            4.864416\n",
       " 7     3493            3.866076\n",
       " 8     3397            3.759823\n",
       " 9     1896            2.098506\n",
       " 10    4067            4.501384"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the count of each V204 response\n",
    "abortion_summary = pd.DataFrame(wvs_df.groupby('V204').V204.count())\n",
    "#Renaming the column\n",
    "abortion_summary.columns = [\"Count\"]\n",
    "# Creating the Percentage column\n",
    "abortion_summary[\"Percentage_Opinion\"] = abortion_summary[\"Count\"] *100 / len(wvs_df)\n",
    "abortion_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. (4pt) Now remove missings. \n",
    "\n",
    "We do it in two ways:\n",
    "\n",
    "(a) remove everything that are not positive integers for V204 and V2 (country).\n",
    "\n",
    "(b) for all other variables, remove the missings in the sense of missing value on computer. \n",
    "\n",
    "You may leave negative answers in the data, otherwise I am afraid your sample size collapses. What is the final number of observations?\n",
    "\n",
    "Answer 3:\n",
    "\n",
    "The new dataset has 79267 observations after removing the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 328)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part (a)\n",
    "#  Removing everything not positive for V204 \n",
    "wvs_clean_df = wvs_df[wvs_df.V204 > 0]\n",
    "#  Removing everything not positive for V2 \n",
    "wvs_clean_df = wvs_clean_df[wvs_clean_df.V2 > 0]\n",
    "\n",
    "# Part (b)\n",
    "\n",
    "# Dropping all Nas\n",
    "wvs_clean_df = wvs_clean_df.dropna()\n",
    "wvs_clean_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. (2pt) In order to simplify the analysis below, create a new binary variable abortion as abortion =\n",
    "\n",
    "1: V204 > 3\n",
    "\n",
    "0: otherwise\n",
    "\n",
    "Answer 4:\n",
    "\n",
    "We have created a new binary variable \"abortion\" as specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new binary varibale abortion\n",
    "wvs_clean_df['abortion'] = np.where(wvs_clean_df[\"V204\"] > 3 , 1 , 0)\n",
    "# Unique values of new variable abortion\n",
    "wvs_clean_df['abortion'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. (5pt) Compute (pearson) correlation table between abortion and all other variables in the data. There are many of these!\n",
    "Take a look at a few variables that have strong correlation with abortion. What do these represent?\n",
    "\n",
    "Answer 5:\n",
    "\n",
    "From the correlation table,we can see that apart from V204 i.e justification for abortion other variable V205 i.e is divorce jsutifiable? variable has the correlation 0.55 with our response variable abortion. It means that the people (respondents) who find abortion justifiable also feel that divorce is justifiable too and vice versa. The other variables have correlation less then 0.5 and thus have low correlation with our repsonse variable abortion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>abortion</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V204</td>\n",
       "      <td>0.881048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V205</td>\n",
       "      <td>0.548653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V203</td>\n",
       "      <td>0.485419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V206</td>\n",
       "      <td>0.446394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V138</td>\n",
       "      <td>-0.142894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V255</td>\n",
       "      <td>-0.149844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V223</td>\n",
       "      <td>-0.165924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V252</td>\n",
       "      <td>-0.191483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V152</td>\n",
       "      <td>-0.315280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Correlation\n",
       "abortion     1.000000\n",
       "V204         0.881048\n",
       "V205         0.548653\n",
       "V203         0.485419\n",
       "V206         0.446394\n",
       "...               ...\n",
       "V138        -0.142894\n",
       "V255        -0.149844\n",
       "V223        -0.165924\n",
       "V252        -0.191483\n",
       "V152        -0.315280\n",
       "\n",
       "[328 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting correlation of all predictors with our response variable abortion\n",
    "wvs_abor_cor = pd.DataFrame(wvs_clean_df[wvs_clean_df.columns[1:]].corr()['abortion'][:])\n",
    "# Sorting the correlation in descending order\n",
    "wvs_abor_cor_sor = wvs_abor_cor.sort_values(by='abortion', ascending=False)\n",
    "#Renaming the column\n",
    "wvs_abor_cor_sor.columns = [\"Correlation\"]\n",
    "wvs_abor_cor_sor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. (4pt) convert country code V2 into dummies. First rename V2 to country. Thereafter use pd.get_dummies along these lines. Afterwards, remove country variable from the data. How many rows/columns do you have now? How many country dummies does the data contain?\n",
    "\n",
    "Answer 6: \n",
    "\n",
    "After converting the V2 variable to country dummies, the data has 79267 rows and 386 columns. After removing one dummy variable, the dataset will have 385 variables\n",
    "\n",
    "Our dataset contains 58 contry dummy variables. We have removed one country dummy variable \"country_12\" in order to avoid perfect multicollinearity. Now the dataset has 57 variables country dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   V4  V5  V6  V7  V8  V9  V10  V11  V12  V13  ...  country_752  country_764  \\\n",
      "0   1   1   1  -2   1   1    2    1    1    1  ...            0            0   \n",
      "1   1   2   3   4   2   2    2    2    2    1  ...            0            0   \n",
      "2   1   3   2   4   2   1    2    2    2    2  ...            0            0   \n",
      "3   1   1   3   4   3   1    2    1    2    2  ...            0            0   \n",
      "4   1   1   1   2   1   1    1    3    2    1  ...            0            0   \n",
      "\n",
      "   country_780  country_788  country_792  country_804  country_840  \\\n",
      "0            0            0            0            0            0   \n",
      "1            0            0            0            0            0   \n",
      "2            0            0            0            0            0   \n",
      "3            0            0            0            0            0   \n",
      "4            0            0            0            0            0   \n",
      "\n",
      "   country_858  country_860  country_887  \n",
      "0            0            0            0  \n",
      "1            0            0            0  \n",
      "2            0            0            0  \n",
      "3            0            0            0  \n",
      "4            0            0            0  \n",
      "\n",
      "[5 rows x 386 columns]\n",
      "\n",
      "The number of rows and columns are : \n",
      "(79267, 386)\n"
     ]
    }
   ],
   "source": [
    "# Renaming V2 to country\n",
    "wvs_clean_df.rename(columns={'V2':'country'} , inplace=True)\n",
    "# Creating dummy varibales for country\n",
    "wvs_country_df = pd.get_dummies(wvs_clean_df, columns = ['country'])\n",
    "\n",
    "print(wvs_country_df.head())\n",
    "\n",
    "print(\"\\nThe number of rows and columns are : \")\n",
    "print(wvs_country_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country dummy varibales\n",
      "\n",
      "['country_12', 'country_31', 'country_32', 'country_36', 'country_48', 'country_51', 'country_76', 'country_112', 'country_152', 'country_156', 'country_158', 'country_170', 'country_196', 'country_218', 'country_233', 'country_268', 'country_275', 'country_276', 'country_288', 'country_344', 'country_356', 'country_368', 'country_392', 'country_398', 'country_400', 'country_410', 'country_417', 'country_422', 'country_434', 'country_458', 'country_484', 'country_504', 'country_528', 'country_554', 'country_566', 'country_586', 'country_604', 'country_608', 'country_616', 'country_634', 'country_642', 'country_643', 'country_646', 'country_702', 'country_705', 'country_710', 'country_716', 'country_724', 'country_752', 'country_764', 'country_780', 'country_788', 'country_792', 'country_804', 'country_840', 'country_858', 'country_860', 'country_887']\n",
      "\n",
      "Number of country dummy variables :  58\n",
      "\n",
      "The country dummy varibales after removing one variable\n",
      "\n",
      "['country_31', 'country_32', 'country_36', 'country_48', 'country_51', 'country_76', 'country_112', 'country_152', 'country_156', 'country_158', 'country_170', 'country_196', 'country_218', 'country_233', 'country_268', 'country_275', 'country_276', 'country_288', 'country_344', 'country_356', 'country_368', 'country_392', 'country_398', 'country_400', 'country_410', 'country_417', 'country_422', 'country_434', 'country_458', 'country_484', 'country_504', 'country_528', 'country_554', 'country_566', 'country_586', 'country_604', 'country_608', 'country_616', 'country_634', 'country_642', 'country_643', 'country_646', 'country_702', 'country_705', 'country_710', 'country_716', 'country_724', 'country_752', 'country_764', 'country_780', 'country_788', 'country_792', 'country_804', 'country_840', 'country_858', 'country_860', 'country_887']\n",
      "\n",
      "Number of country dummy variables :  57\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "# Country dummy variables\n",
    "filter_col = [col for col in wvs_country_df if col.startswith('country')]\n",
    "print(\"The country dummy varibales\\n\")\n",
    "print(filter_col)\n",
    "print(\"\\nNumber of country dummy variables : \",len(filter_col))\n",
    "\n",
    "# Dropping one country dummy variable\n",
    "wvs_country_df  = wvs_country_df.drop('country_12', axis =1)\n",
    "\n",
    "filter_col = [col for col in wvs_country_df if col.startswith('country')]\n",
    "print(\"\\nThe country dummy varibales after removing one variable\\n\")\n",
    "print(filter_col)\n",
    "print(\"\\nNumber of country dummy variables : \",len(filter_col))\n",
    "print(len(filter_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Implement Cross-Validation (40pt)\n",
    "Now it's time to write your own code that does k-fold CV. I recommend to go the following path:\n",
    "\n",
    "(3pt) Make it as a function that takes k, the (unffitted) model, features X and the target y as arguments.\n",
    "(10pt) Next, one should randomly shufflee the data. However, it is easier to generate a list of indices, and shuffle those randomly.\n",
    "(25pt) Loop the following k times\n",
    "(a) Select every k-th of your indices for validation data\n",
    "\n",
    "(b) For training data, select all indices, except those that went into validation data. Hint: check out set operations\n",
    "\n",
    "(c) Separate the data X and the target y into training/validation parts.\n",
    "\n",
    "(d) Fit the model on training data\n",
    "\n",
    "(e) Predict outcome on validation data\n",
    "\n",
    "(f) Compute the resulting statistic (you may compute more than one).\n",
    "\n",
    "(2pt) Finally, return mean of the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import preprocessing\n",
    "from statistics import mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for k-fold cross \n",
    "def k_fold_cross_val(k , model , x , y):\n",
    "    frames = [x,y]\n",
    "    # Creating a dataset with target and features\n",
    "    dataset = pd.concat(frames, axis =1)\n",
    "    # Getting the target column name\n",
    "    response_var=y.columns\n",
    "    # Getting the features column names\n",
    "    predictor_var= x.columns\n",
    "    # Creating lists to store statistics\n",
    "    fscore=[]\n",
    "    accuracy=[]\n",
    "    precision =[]\n",
    "    recall =[]\n",
    "    \n",
    "    # Randomly shuffling the data\n",
    "    model_shuffled = dataset.sample(frac=1)\n",
    "    \n",
    "    # Splitting the data in k parts\n",
    "    folds = np.array_split(dataset, k)\n",
    "\n",
    "    for i in range(k):\n",
    "        # Creating the training and testing data\n",
    "        train_data = folds.copy()\n",
    "        test_data = folds[i]\n",
    "        del train_data[i]\n",
    "        train_data = pd.concat(train_data, sort=False) \n",
    "        \n",
    "        # Getting the response and predictors from training and testing data\n",
    "        response_train = train_data[response_var]\n",
    "        pred_train=train_data[predictor_var]\n",
    "        response_test = test_data[response_var]\n",
    "        pred_test =test_data[predictor_var]         \n",
    "\n",
    "        # Fitting the model\n",
    "        fitted_mod = model.fit(pred_train,response_train)\n",
    "        # Predicting the model\n",
    "        pred= fitted_mod.predict(pred_test)\n",
    "\n",
    "        # Storing the statistics\n",
    "        accuracy.append(accuracy_score(pred,response_test))\n",
    "        fscore.append(f1_score(pred,response_test, average=\"binary\"))\n",
    "        precision.append(precision_score(pred,response_test))\n",
    "        recall.append(recall_score(pred,response_test))\n",
    "    \n",
    "    # Creating a list and returning all the mean statistics\n",
    "    res = [mean(accuracy), mean(fscore), mean(precision), mean(recall)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Find the best model (40)\n",
    "In this section your task is to nfid which model: k-NN, logistic regression, or SVM works best. You will evaluate the model performance using 5-fold cross-validation with accuracy and F-score as the metric. And unlike in all your future work, here you will use your own CV impementation. Some of the methods (k-NN, SVM) are slow to compute, so you may start with a subset of data (say, 5000 random lines only). If everything turns out fine, you increase the data size as far as your computer can go.\n",
    "\n",
    "## 3.1 k-NN (13pt)\n",
    "First, use k-NN and experiment with a few different k-s.\n",
    "\n",
    "Q1. (2pt) Separate your training data into X (features), and y (target). Target will be the abortion variable, X are all the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate data into X (features), and y (target). Target will be the abortion variable, X are all the other features.\n",
    "wvs_sample_df=pd.DataFrame(wvs_country_df.sample(10000))\n",
    "y=pd.DataFrame(wvs_sample_df[\"abortion\"]) #response variable\n",
    "x=pd.DataFrame(wvs_sample_df.loc[:, wvs_sample_df.columns != 'abortion']) #predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. (2pt) pick a k and set up the k-NN model. Use your freshly-minted CV routine to cross-validate accuracy and F-score of your k-NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean accuracy for the model is  :  0.8079000000000001\n",
      "\n",
      "The mean f-score for the model is :  0.6965134376364082\n",
      "\n",
      "The mean precision score for the model is :  0.6102595805409806\n",
      "\n",
      "The mean recall score for the model is :  0.8116744646583759\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Taking k as 10\n",
    "knn_mod1=KNeighborsClassifier(n_neighbors=10)\n",
    "res_knn_mod1 = k_fold_cross_val(5,knn_mod1,x,y)\n",
    "print('\\nThe mean accuracy for the model is  : ', res_knn_mod1[0])\n",
    "print('\\nThe mean f-score for the model is : ', res_knn_mod1[1])\n",
    "print('\\nThe mean precision score for the model is : ', res_knn_mod1[2])\n",
    "print('\\nThe mean recall score for the model is : ', res_knn_mod1[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. (5pt) Try a few different k-NN models (pick different k, choose to normalize/not-to-normalize your features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean accuracy for the model is  :  0.8099\n",
      "\n",
      "The mean f-score for the model is :  0.700268943632546\n",
      "\n",
      "The mean precision score for the model is :  0.6149164401604876\n",
      "\n",
      "The mean recall score for the model is :  0.8141304666434743\n"
     ]
    }
   ],
   "source": [
    "# Taking k as 50\n",
    "knn_mod2=KNeighborsClassifier(n_neighbors=50)\n",
    "res_knn_mod2 = k_fold_cross_val(5,knn_mod2,x,y)\n",
    "print('\\nThe mean accuracy for the model is  : ', res_knn_mod2[0])\n",
    "print('\\nThe mean f-score for the model is : ', res_knn_mod2[1])\n",
    "print('\\nThe mean precision score for the model is : ', res_knn_mod2[2])\n",
    "print('\\nThe mean recall score for the model is : ', res_knn_mod2[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean accuracy for the model is  :  0.8069000000000001\n",
      "\n",
      "The mean f-score for the model is :  0.6866929855801174\n",
      "\n",
      "The mean precision score for the model is :  0.5857927162472909\n",
      "\n",
      "The mean recall score for the model is :  0.8304242899367473\n"
     ]
    }
   ],
   "source": [
    "# Taking k as 100\n",
    "knn_mod3=KNeighborsClassifier(n_neighbors=100)\n",
    "knn_res_mod3 = k_fold_cross_val(5,knn_mod3,x,y)\n",
    "print('\\nThe mean accuracy for the model is  : ', knn_res_mod3[0])\n",
    "print('\\nThe mean f-score for the model is : ', knn_res_mod3[1])\n",
    "print('\\nThe mean precision score for the model is : ', knn_res_mod3[2])\n",
    "print('\\nThe mean recall score for the model is : ', knn_res_mod3[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. (4pt) Present the results from your best k-NN model. Note: as you are using two metrics here, you may end up with different models performing better according to different measures.\n",
    "\n",
    "Answer 4 : I have run the model for a sample of 10000 and I tried k-NN model with different values : 10, 50 and 100.\n",
    "\n",
    "The best model according to the accuracy and fscore both is k-NN having 50 neighbours. The accuracy of the this model is around 0.81 and the fscore is around 0.70. The mean precision is 0.61 and mean recall is 0.81, which are good. But, k-NN has low computational speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statistics for best k-NN model are : \n",
      "\n",
      "\n",
      "The mean accuracy for the best k-NN model is  :  0.8099\n",
      "\n",
      "The mean f-score for the best k-NN model is :  0.700268943632546\n",
      "\n",
      "The mean precision score for the best k-NN model is :  0.6149164401604876\n",
      "\n",
      "The mean recall score for the best k-NN model is :  0.8141304666434743\n"
     ]
    }
   ],
   "source": [
    "print(\"The statistics for best k-NN model are : \\n\")\n",
    "print('\\nThe mean accuracy for the best k-NN model is  : ', res_knn_mod2[0])\n",
    "print('\\nThe mean f-score for the best k-NN model is : ', res_knn_mod2[1])\n",
    "print('\\nThe mean precision score for the best k-NN model is : ', res_knn_mod2[2])\n",
    "print('\\nThe mean recall score for the best k-NN model is : ', res_knn_mod2[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Logistic Regression (9pt)\n",
    "\n",
    "Q1.Now repeat the process above with logistic regression. As we have a myriad of features anyway, we are not going to do any feature engineering. Just a plain logistic regression.\n",
    "\n",
    "Response: \n",
    "The mean accuracy and f score for logistic regression with our sample 10000 is 0.999 i.e around 1. When we run logistic regression for the whole dataset , we get the accuracy and f-score both as 1.\n",
    "\n",
    "Also, logistic regression has high computational speed. We are able to sample and train all of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean accuracy for the model is  :  0.9999\n",
      "\n",
      "The mean f-score for the model is :  0.9998582565556343\n",
      "\n",
      "The mean precision score for the model is :  0.9997167138810198\n",
      "\n",
      "The mean recall score for the model is :  1.0\n"
     ]
    }
   ],
   "source": [
    "# Running Logistic Regression Model\n",
    "lr_mod1=LogisticRegression()\n",
    "lr_res_mod1 = k_fold_cross_val(5,lr_mod1,x,y)\n",
    "print('\\nThe mean accuracy for the model is  : ', lr_res_mod1[0])\n",
    "print('\\nThe mean f-score for the model is : ', lr_res_mod1[1])\n",
    "print('\\nThe mean precision score for the model is : ', lr_res_mod1[2])\n",
    "print('\\nThe mean recall score for the model is : ', lr_res_mod1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean accuracy for the model is  :  1.0\n",
      "\n",
      "The mean f-score for the model is :  1.0\n",
      "\n",
      "The mean precision score for the model is :  1.0\n",
      "\n",
      "The mean recall score for the model is :  1.0\n"
     ]
    }
   ],
   "source": [
    "# Taking the whole sample for logistic regression\n",
    "y_log =pd.DataFrame(wvs_country_df[\"abortion\"]) #response variable\n",
    "x_log =pd.DataFrame(wvs_country_df.loc[:, wvs_sample_df.columns != 'abortion']) #predictors\n",
    "\n",
    "# Running Logistic Regression Model\n",
    "lr_mod2=LogisticRegression()\n",
    "lr_res_mod2 = k_fold_cross_val(5,lr_mod2,x_log,y_log)\n",
    "print('\\nThe mean accuracy for the model is  : ', lr_res_mod2[0])\n",
    "print('\\nThe mean f-score for the model is : ', lr_res_mod2[1])\n",
    "print('\\nThe mean precision score for the model is : ', lr_res_mod2[2])\n",
    "print('\\nThe mean recall score for the model is : ', lr_res_mod2[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SVM (15pt)\n",
    "\n",
    "Now repeat the process with support vector machines while choosing between a few different kernels and kernel options, such as degree for polynomial kernels.\n",
    "\n",
    "Hint: I have mixed experience with sklearn version of SVM. I recommend to limit the number of iterations, initially maybe to just 1000, in order to ensure your model actually terminates.\n",
    "\n",
    "Q1. (14pt) pick a kernel and repeat the process above. Note that some kernels are slower than others, so be careful.\n",
    "\n",
    "Answer 1 : For SVM, I have run the model for a sample of 10000 and used kernal linear and poly with 8 degree. \n",
    "\n",
    "For SVM model with linear kernal , the mean accuracy and the mean fscore both are one. The precision and recall are too 1.\n",
    "\n",
    "For SVM model with poly kernal and degree 8 , the mean accuracy is 0.97 and mean fscore is 0.96. The mean precision score for this model is 0.94 and mean recall is 0.96.\n",
    "\n",
    "We can see that the accuracy and fscore are high , but the SVM model has low computational speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean accuracy for the model is  :  1.0\n",
      "\n",
      "The mean f-score for the model is :  1.0\n",
      "\n",
      "The mean precision score for the model is :  1.0\n",
      "\n",
      "The mean recall score for the model is :  1.0\n"
     ]
    }
   ],
   "source": [
    "# SVC model with kernal linear\n",
    "svc_mod1 =SVC(kernel=\"linear\")\n",
    "svm_res_mod = k_fold_cross_val(5,svc_mod1,x,y)\n",
    "\n",
    "print('\\nThe mean accuracy for the model is  : ', svm_res_mod[0])\n",
    "print('\\nThe mean f-score for the model is : ', svm_res_mod[1])\n",
    "print('\\nThe mean precision score for the model is : ', svm_res_mod[2])\n",
    "print('\\nThe mean recall score for the model is : ', svm_res_mod[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean accuracy for the model is  :  0.9701\n",
      "\n",
      "The mean f-score for the model is :  0.958212415442607\n",
      "\n",
      "The mean precision score for the model is :  0.9489339840751684\n",
      "\n",
      "The mean recall score for the model is :  0.9677406630926889\n"
     ]
    }
   ],
   "source": [
    "# SVC model with kernal poly\n",
    "svm_mod2 = SVC(kernel='poly', degree=8)\n",
    "\n",
    "svm_res_mod2 = k_fold_cross_val(5,svm_mod2,x,y)\n",
    "\n",
    "print('\\nThe mean accuracy for the model is  : ', svm_res_mod2[0])\n",
    "print('\\nThe mean f-score for the model is : ', svm_res_mod2[1])\n",
    "print('\\nThe mean precision score for the model is : ', svm_res_mod2[2])\n",
    "print('\\nThe mean recall score for the model is : ', svm_res_mod2[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. (2pt) If your models worked like mine, you may have noticed that while accuracy seems all right, precision and recall are rather low. Explain what does such a phenomenon mean.\n",
    "\n",
    "Answer 2: \n",
    "\n",
    "Accuracy is the fraction of predictions our model got right. It is the rato of right predictions to the total number of predictions. Accuarcy is a good metric to consider when the dataset is balanced i.e  we have same samples for each case. But, in many real-life problems, most datasets  have imbalanced data it becomes necessary to consider other metrics like precision and recall score.\n",
    "\n",
    "In our case, a false positive would mean having wrongly classified a person who thinks abortion is not justifiable as a person who thinks abortion is justifiable. A false negative would mean having classified a person who thinks abortion is justifiable as a person who thinks abortion is not justifiable.\n",
    "\n",
    "Precision is defined as the number of true positives divided by the number of true positives plus the number of false  positives (i.e the total positives identified by the model). The precision score expresses the proportion of the data points our model says was relevant actually were relevant. \n",
    "\n",
    "Recall is defined as the number of true positives divided by the number of true positives plus the number of false negatives.It is the ability of a model to find all the relevant cases within a dataset.\n",
    "\n",
    "Having a high accuracy and low precision and recall score means that very few positives are actually true and also that most of the times our true poistive values are never predicted. A good model should try to minimize the false positives and false negatives along with correctly classifying data. Thus, a model with high accuracy and low precision and recall  is not ideal model, especially if the cost of the false positives and false negatives classifications are high.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Compare the models (3pt)\n",
    "\n",
    "Q1. (2pt) Finally, compare the models. Which ones performed the best in terms of accuracy? Which ones in terms of F-score? Did you encounter other kind of issues with certain models? Which models were fast and which ones slow?\n",
    "\n",
    "Answer 1 : The logstic regression and the SVM with linear kernal has the best mean accuracy and best mean f-score with value 1. K-NN has lower accuracy and fscore. The SVC with poly kernal and degree 8 has a good accuracy of 97 and fscore of 96. The logical regression has high computational speed and was fast. I was able to run the regression model on whole dataset as well in a decent time. K-NN and SVM were slow and i ran the model only on the sample of 10000, which was also very slow. I did not face any other issues except the computation time.\n",
    "\n",
    "Q2. (1pt) If you have to repeat the exercise with a single model (and you have, see below), which one will you pick?\n",
    "\n",
    "Answer 2 : If I had to repeat the exercise with a single model, I would select logistic regression for this dataset, as it gives us higher accuracy and fscore of 1. The precision and recall is also good for the logistic regression model. Plus, it has high computational speed and it is fast. Also, I could run my logistic model on sample as well as my whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 How large a role does country play? (20pt)\n",
    "Here we switch from machine learning to social sciences. Public opinion differs from country to country, but also inside the countries. Does the fact that we include country code in data help us to substantially\n",
    "improve the predictions?\n",
    "You pick the best ML method from above. You estimate two sets of models: one with country information included, and one where it is removed. Is the former noticeably better than the latter?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. (10pt) Pick your best ML method based you designed above. Cross-validate the accuracy of abortion variable using all the features, including country dummies and report the accuracy. Essentially you repeat here what you did above, so you can also just copy the result from above\n",
    "\n",
    "Answer 1 : For me, the best ML methot for this dataset is Logistic Regression,  as it gives us higher accuracy and fscore  of 1 for this dataset. The precision and recall is also good for the model. Plus, it has high computational speed and it is fast. Also, I could run my logistic model on sample of 10000 as well as my whole dataset.\n",
    "\n",
    "The mean accuracy and f score for logistic regression with our sample 10000 is 0.999 i.e around 1. When we run logistic regression for the whole dataset , we get the accuracy and f-score both as 1. The precision and recall score for the model is also 1.\n",
    "\n",
    "Also, logistic regression has high computational speed. We are able to sample and train all of our dataset.\n",
    "\n",
    "The exact results are show below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for logistic Regression model with sample of 10000 are :\n",
      "\n",
      "The mean accuracy for logistic Regression model with sample of 10000 is  :  0.9999\n",
      "\n",
      "The mean f-score for logistic Regression model with sample of 10000 :  0.9998582565556343\n",
      "\n",
      "The mean precision score for logistic Regression model with sample of 10000 is :  0.9997167138810198\n",
      "\n",
      "The mean recall score for logistic Regression model with sample of 10000 is :  1.0\n",
      "\n",
      "The results for logistic Regression model with whole dataset are : \n",
      "\n",
      "The mean accuracy logistic Regression model with whole dataset is  :  1.0\n",
      "\n",
      "The mean f-score for logistic Regression model with whole dataset is :  1.0\n",
      "\n",
      "The mean precision score for logistic Regression model with whole dataset is :  1.0\n",
      "\n",
      "The mean recall score for logistic Regression model with whole dataset is :  1.0\n"
     ]
    }
   ],
   "source": [
    "print('The results for logistic Regression model with sample of 10000 are :')\n",
    "print('\\nThe mean accuracy for logistic Regression model with sample of 10000 is  : ', lr_res_mod1[0])\n",
    "print('\\nThe mean f-score for logistic Regression model with sample of 10000 : ', lr_res_mod1[1])\n",
    "print('\\nThe mean precision score for logistic Regression model with sample of 10000 is : ', lr_res_mod1[2])\n",
    "print('\\nThe mean recall score for logistic Regression model with sample of 10000 is : ', lr_res_mod1[3])\n",
    "\n",
    "print('\\nThe results for logistic Regression model with whole dataset are : ')\n",
    "print('\\nThe mean accuracy logistic Regression model with whole dataset is  : ', lr_res_mod2[0])\n",
    "print('\\nThe mean f-score for logistic Regression model with whole dataset is : ', lr_res_mod2[1])\n",
    "print('\\nThe mean precision score for logistic Regression model with whole dataset is : ', lr_res_mod2[2])\n",
    "print('\\nThe mean recall score for logistic Regression model with whole dataset is : ', lr_res_mod2[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. (15pt) Now remove all the country dummies, but keep the other variables intact. And repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statistics for the logistic model without country variables are : \n",
      "\n",
      "The mean accuracy for the model is  :  1.0\n",
      "\n",
      "The mean f-score for the model is :  1.0\n",
      "\n",
      "The mean precision score for the model is :  1.0\n",
      "\n",
      "The mean recall score for the model is :  1.0\n"
     ]
    }
   ],
   "source": [
    "# Removing the country dummy variables\n",
    "wvs_wo_country_df = wvs_country_df.drop(filter_col, axis =1)\n",
    "wvs_wo_country_df.columns\n",
    "\n",
    "# Taking the sample for logistic regression without country\n",
    "y_country =pd.DataFrame(wvs_wo_country_df[\"abortion\"]) #response variable\n",
    "x_country =pd.DataFrame(wvs_wo_country_df.loc[:, wvs_wo_country_df.columns != 'abortion']) #predictors\n",
    "\n",
    "# Running Logistic Regression Model\n",
    "lr_mod3=LogisticRegression()\n",
    "lr_res_mod3 = k_fold_cross_val(5,lr_mod3,x_country,y_country)\n",
    "print('The statistics for the logistic model without country variables are : ')\n",
    "print('\\nThe mean accuracy for the model is  : ', lr_res_mod3[0])\n",
    "print('\\nThe mean f-score for the model is : ', lr_res_mod3[1])\n",
    "print('\\nThe mean precision score for the model is : ', lr_res_mod3[2])\n",
    "print('\\nThe mean recall score for the model is : ', lr_res_mod3[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic model gave accuracy 1 earlier. Removing the country variables have not affected the accuracy of fcore. I will aslo try to run the SVM model with kernal poly and degree 8 on this new dataset without country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statistics for SVM model after removing country variables are : \n",
      "\n",
      "The mean accuracy for the model is  :  0.9701\n",
      "\n",
      "The mean f-score for the model is :  0.958212415442607\n",
      "\n",
      "The mean precision score for the model is :  0.9489339840751684\n",
      "\n",
      "The mean recall score for the model is :  0.9677406630926889\n"
     ]
    }
   ],
   "source": [
    "wvs_wo_country_sample_df = wvs_wo_country_df.sample(n =10000)\n",
    "# Taking the sample for SVM without country\n",
    "y_country =pd.DataFrame(wvs_wo_country_sample_df[\"abortion\"]) #response variable\n",
    "x_country =pd.DataFrame(wvs_wo_country_sample_df.loc[:, wvs_wo_country_sample_df.columns != 'abortion']) #predictors\n",
    "\n",
    "svm_mod3 = SVC(kernel='poly', degree=8)\n",
    "\n",
    "svm_res_mod3 = k_fold_cross_val(5,svm_mod3,x,y)\n",
    "\n",
    "print(\"The statistics for SVM model after removing country variables are : \")\n",
    "print('\\nThe mean accuracy for the model is  : ', svm_res_mod3[0])\n",
    "print('\\nThe mean f-score for the model is : ', svm_res_mod3[1])\n",
    "print('\\nThe mean precision score for the model is : ', svm_res_mod3[2])\n",
    "print('\\nThe mean recall score for the model is : ', svm_res_mod3[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. (5pt) Comment what you found. Does country information help to noticeably improve the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As, we can see from statistics of the logistic regression model as well as the SVM model that the accuracy and the fscore was not affected by removing the country variables.Thus, we can say that the country information has not noticeably impoved the prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
